{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"wQbhFTw3p3PR","executionInfo":{"status":"ok","timestamp":1712480593574,"user_tz":-540,"elapsed":451,"user":{"displayName":"최다솔(일반대학원 디지털애널리틱스 융합협동과정)","userId":"06217896809786522271"}}},"outputs":[],"source":["import os\n","import sys\n","\n","os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""]},{"cell_type":"code","source":["!pip install pytorch-ood"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t9IsKIRhqAYS","executionInfo":{"status":"ok","timestamp":1712480683688,"user_tz":-540,"elapsed":89577,"user":{"displayName":"최다솔(일반대학원 디지털애널리틱스 융합협동과정)","userId":"06217896809786522271"}},"outputId":"db57bcc0-b77a-4a32-c692-7acf06a8b6ab"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pytorch-ood\n","  Downloading pytorch_ood-0.1.7-py3-none-any.whl (120 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.1/120.1 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-ood) (2.2.1+cu121)\n","Requirement already satisfied: torchvision>=0.12.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-ood) (0.17.1+cu121)\n","Collecting torchmetrics>=1.0.0 (from pytorch-ood)\n","  Downloading torchmetrics-1.3.2-py3-none-any.whl (841 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m841.5/841.5 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-ood) (1.11.4)\n","Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-ood) (1.25.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->pytorch-ood) (3.13.3)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->pytorch-ood) (4.10.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->pytorch-ood) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->pytorch-ood) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->pytorch-ood) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->pytorch-ood) (2023.6.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.7.0->pytorch-ood)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.7.0->pytorch-ood)\n","  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.7.0->pytorch-ood)\n","  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.7.0->pytorch-ood)\n","  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.7.0->pytorch-ood)\n","  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.7.0->pytorch-ood)\n","  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.7.0->pytorch-ood)\n","  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.7.0->pytorch-ood)\n","  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.7.0->pytorch-ood)\n","  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch>=1.7.0->pytorch-ood)\n","  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.7.0->pytorch-ood)\n","  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->pytorch-ood) (2.2.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.7.0->pytorch-ood)\n","  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m64.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging>17.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics>=1.0.0->pytorch-ood) (24.0)\n","Collecting lightning-utilities>=0.8.0 (from torchmetrics>=1.0.0->pytorch-ood)\n","  Downloading lightning_utilities-0.11.2-py3-none-any.whl (26 kB)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.12.0->pytorch-ood) (9.4.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics>=1.0.0->pytorch-ood) (67.7.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7.0->pytorch-ood) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7.0->pytorch-ood) (1.3.0)\n","Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, lightning-utilities, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torchmetrics, pytorch-ood\n","Successfully installed lightning-utilities-0.11.2 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 pytorch-ood-0.1.7 torchmetrics-1.3.2\n"]}]},{"cell_type":"code","execution_count":3,"metadata":{"id":"lBo2Yf4Cp3PU","executionInfo":{"status":"ok","timestamp":1712480691756,"user_tz":-540,"elapsed":8069,"user":{"displayName":"최다솔(일반대학원 디지털애널리틱스 융합협동과정)","userId":"06217896809786522271"}}},"outputs":[],"source":["import numpy as np\n","import torch\n","import torchvision\n","import torchvision.transforms as tvt\n","from torch.utils.data import DataLoader\n","from torchvision.datasets import CIFAR10, CIFAR100, SVHN, Places365\n","\n","from pytorch_ood.dataset.img import (\n","    LSUNCrop,\n","    Textures,\n","    TinyImageNetCrop,\n","    GaussianNoise\n",")\n","from pytorch_ood.detector import (\n","    ODIN,\n","    EnergyBased,\n","    Entropy,\n","    KLMatching,\n","    Mahalanobis,\n","    MaxLogit,\n","    MaxSoftmax,\n","    ViM,\n",")\n","from pytorch_ood.model import WideResNet\n","from pytorch_ood.utils import OODMetrics, ToRGB, ToUnknown\n","\n","torch.manual_seed(1234)\n","\n","mean = [x / 255 for x in [125.3, 123.0, 113.9]]\n","std = [x / 255 for x in [63.0, 62.1, 66.7]]\n","\n","trans = tvt.Compose([\n","    tvt.Resize(size=(32, 32)),\n","    ToRGB(),\n","    tvt.ToTensor(),\n","    tvt.Normalize(std=std, mean=mean)\n","])"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"YnWpKCJRp3PW","executionInfo":{"status":"ok","timestamp":1712480691757,"user_tz":-540,"elapsed":64,"user":{"displayName":"최다솔(일반대학원 디지털애널리틱스 융합협동과정)","userId":"06217896809786522271"}}},"outputs":[],"source":["def calculate(test_loader, detector):\n","    metrics = OODMetrics() # Evaluate Detectors\n","\n","    print(\"Total count:\", len(test_loader))\n","    cnt = 0\n","    for x, y in test_loader:\n","        metrics.update(detector(x.cuda()), y)\n","        cnt += 1\n","        if (cnt + 1) % 50 == 0:\n","            print(f\"[{cnt}/{len(test_loader)}]\")\n","\n","    r = metrics.compute()\n","    print(r)\n","    return r"]},{"cell_type":"code","source":["def test_with_all_datasets(detector, base_dataset, transform=trans, batch_size=128, num_workers=20):\n","    dataset_names = [\"SVHN\", \"Textures\", \"LSUNCrop\", \"TinyImageNetCrop\", \"Places365\", \"GaussianNoise\"]\n","    results = []\n","\n","    for name in dataset_names:\n","        if name == \"SVHN\":\n","            dataset_out_test = SVHN(root=\"data\", split=\"test\", download=True, transform=transform, target_transform=ToUnknown())\n","        elif name == \"Textures\":\n","            dataset_out_test = Textures(root=\"data\", download=True, transform=transform, target_transform=ToUnknown())\n","        elif name == \"LSUNCrop\":\n","            dataset_out_test = LSUNCrop(root=\"data\", download=True, transform=transform, target_transform=ToUnknown())\n","        elif name == \"TinyImageNetCrop\":\n","            dataset_out_test = TinyImageNetCrop(root=\"data\", download=True, transform=transform, target_transform=ToUnknown())\n","        elif name == \"Places365\":\n","            dataset_out_test = Places365(root=\"data\", split=\"val\", small=True, transform=transform, target_transform=ToUnknown())\n","        elif name == \"GaussianNoise\":\n","            dataset_out_test = GaussianNoise(length=10000, transform=transform, target_transform=ToUnknown(), download=True)\n","        else:\n","            continue\n","\n","        test_loader = DataLoader(torch.utils.data.ConcatDataset([base_dataset, dataset_out_test]), batch_size=batch_size, num_workers=num_workers)\n","        print()\n","        print(name)\n","        results.append(calculate(test_loader, detector))\n","\n","    return results"],"metadata":{"id":"08qD8Z6dzGOS","executionInfo":{"status":"ok","timestamp":1712480691758,"user_tz":-540,"elapsed":18,"user":{"displayName":"최다솔(일반대학원 디지털애널리틱스 융합협동과정)","userId":"06217896809786522271"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["### MaxSoftmax"],"metadata":{"id":"YR7Z3MYo0RP-"}},{"cell_type":"code","source":["model = WideResNet(num_classes=100, pretrained=\"cifar100-pt\").cuda().eval()\n","dataset_in_test = CIFAR100(root=\"data\", train=False, download=True, transform=trans)\n","loader_in_train = DataLoader(dataset_in_test, batch_size=128, num_workers=20)\n","\n","detector = MaxSoftmax(model)\n","detector.fit(loader_in_train, device=\"cuda\")\n","results = test_with_all_datasets(detector, dataset_in_test)\n","\n","mean_AUROC = np.mean([r[\"AUROC\"] for r in results])\n","mean_FPR = np.mean([r[\"FPR95TPR\"] for r in results])\n","\n","print(\"AUROC:\", mean_AUROC)\n","print(\"FPR:\", mean_FPR)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T9zIOcOjzOhE","executionInfo":{"status":"ok","timestamp":1712399570309,"user_tz":-540,"elapsed":273253,"user":{"displayName":"최다솔","userId":"02081007897853777168"}},"outputId":"5d24698c-07f4-4a85-8ec5-da6843a77129"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading: \"https://github.com/wetliu/energy_ood/raw/master/CIFAR/snapshots/pretrained/cifar100_wrn_pretrained_epoch_99.pt\" to /root/.cache/torch/hub/checkpoints/wrn-cifar100-pt.pt\n","100%|██████████| 8.66M/8.66M [00:00<00:00, 313MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to data/cifar-100-python.tar.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 169001437/169001437 [00:13<00:00, 12924006.83it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting data/cifar-100-python.tar.gz to data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 20 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"output_type":"stream","name":"stdout","text":["Downloading http://ufldl.stanford.edu/housenumbers/test_32x32.mat to data/test_32x32.mat\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 64275384/64275384 [00:40<00:00, 1592707.03it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","SVHN\n","Total count: 282\n","[49/282]\n","[99/282]\n","[149/282]\n","[199/282]\n","[249/282]\n","{'AUROC': 0.7137823700904846, 'AUPR-IN': 0.8437422513961792, 'AUPR-OUT': 0.5779001116752625, 'FPR95TPR': 0.6929000020027161}\n","Downloading https://thor.robots.ox.ac.uk/datasets/dtd/dtd-r1.0.1.tar.gz to data/textures-r1_0_1.tar.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 625239812/625239812 [00:37<00:00, 16854493.84it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting data/textures-r1_0_1.tar.gz to data\n","\n","Textures\n","Total count: 123\n","[49/123]\n","[99/123]\n","{'AUROC': 0.7354907989501953, 'AUPR-IN': 0.5750514268875122, 'AUPR-OUT': 0.8314752578735352, 'FPR95TPR': 0.7139000296592712}\n","Downloading https://uc381aa430a91a182b3917033da3.dl.dropboxusercontent.com/cd/0/inline2/CQhEWcAatEQH04tRDc8OeTPCZMOXI7yOwIK4uDZr7OiWuT-PicClW7u9fLVQ9Mt5ZtMephm78-t5uKhmMfE9cDCUynTXx1fGzAoKL6jZQlTC-wDyA5DnGSE2X_TbfpPochrGoBqskkmdMSLdVUy_9JwA0j_A_BZDKUfl3VRAVOrPDhK0V0ANi8Uzm6gv0u5K2RTTSLnWNBqXmMVNEHGzfz0z3PJJhrLjsDPdismq-W92gG5FIwuKPn5UXONPd4R4JfoccE04RvRaC6zG4WHrQBgBW34GfDcmyHmYfwMnjL-hho2XRwGjwmbD4OAnTexs9AXtm2R2om6lp_T9gsvy_lTkZfC4izMvzp7sTBQTr-0FxN43vZKiZLnmspilcSnYHcs/file to data/LSUN.tar.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 17309383/17309383 [00:00<00:00, 19451191.68it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting data/LSUN.tar.gz to data\n","\n","LSUNCrop\n","Total count: 157\n","[49/157]\n","[99/157]\n","[149/157]\n","{'AUROC': 0.8558781147003174, 'AUPR-IN': 0.8435630202293396, 'AUPR-OUT': 0.874040961265564, 'FPR95TPR': 0.47130000591278076}\n","Downloading https://uc159b37b986adc56434d18d0db3.dl.dropboxusercontent.com/cd/0/inline2/CQjKwCfVttiXPKcihn8ev5mGz3DEleJjYtioXbuaKrT8xF_v8wxFAitasZz7qRnMqobrDFLKG5EK8RhZUlFtf0FiCmp5uKIih4Cal5coB-Z-9ppysCe4wYzVlz_U4TbBorJtr594Zirsi-gNWLiWV1gP-9fCWp4JBTkv2V59zJ_ldLrVINCV3QIQMxn_vEtLotFCdn8CY39lLkzi-iDeYM7ICH3l656gvPSJJpyLbgWhH98D3d1J17J5D6oCO79oWi23RLWv7AoBd49hQhN5HhNjRsoMSk4QGUupUSI_ZW9USw8asL_AeJnso1zcI_5QEjHNy125Nyivm0KVsnfPvXXUgRGoblJJ6_A8dINDWmerXDnTVYyJKHKkbhZMZgf6AAA/file to data/Imagenet.tar.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 26501958/26501958 [00:01<00:00, 19744713.63it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting data/Imagenet.tar.gz to data\n","\n","TinyImageNetCrop\n","Total count: 157\n","[49/157]\n","[99/157]\n","[149/157]\n","{'AUROC': 0.8632166981697083, 'AUPR-IN': 0.8480734825134277, 'AUPR-OUT': 0.8823279738426208, 'FPR95TPR': 0.4334999918937683}\n","\n","Places365\n","Total count: 364\n","[49/364]\n","[99/364]\n","[149/364]\n","[199/364]\n","[249/364]\n","[299/364]\n","[349/364]\n","{'AUROC': 0.7391895055770874, 'AUPR-IN': 0.8944536447525024, 'AUPR-OUT': 0.5008723139762878, 'FPR95TPR': 0.6991000175476074}\n","\n","GaussianNoise\n","Total count: 157\n","[49/157]\n","[99/157]\n","[149/157]\n","{'AUROC': 0.8067207336425781, 'AUPR-IN': 0.6909393072128296, 'AUPR-OUT': 0.8663459420204163, 'FPR95TPR': 0.39160001277923584}\n","AUROC: 0.7857130368550619\n","FPR: 0.5670500099658966\n"]}]},{"cell_type":"markdown","source":["### ODIN"],"metadata":{"id":"Ew-po0Sp0V8J"}},{"cell_type":"code","source":["model = WideResNet(num_classes=100, pretrained=\"cifar100-pt\").cuda().eval()\n","dataset_in_test = CIFAR100(root=\"data\", train=False, download=True, transform=trans)\n","loader_in_train = DataLoader(dataset_in_test, batch_size=128, num_workers=20)\n","\n","detector = ODIN(model, eps=0.002)\n","detector.fit(loader_in_train, device=\"cuda\")\n","results = test_with_all_datasets(detector, dataset_in_test)\n","\n","mean_AUROC = np.mean([r[\"AUROC\"] for r in results])\n","mean_FPR = np.mean([r[\"FPR95TPR\"] for r in results])\n","\n","print(\"AUROC:\", mean_AUROC)\n","print(\"FPR:\", mean_FPR)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6UpICzLH0Zod","executionInfo":{"status":"ok","timestamp":1712399806759,"user_tz":-540,"elapsed":213952,"user":{"displayName":"최다솔","userId":"02081007897853777168"}},"outputId":"c9f11d03-9c6d-4ab4-b37f-15fea63e619c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Files already downloaded and verified\n","Using downloaded and verified file: data/test_32x32.mat\n","\n","SVHN\n","Total count: 282\n","[49/282]\n","[99/282]\n","[149/282]\n","[199/282]\n","[249/282]\n","{'AUROC': 0.646986186504364, 'AUPR-IN': 0.7865357398986816, 'AUPR-OUT': 0.5167717933654785, 'FPR95TPR': 0.736299991607666}\n","\n","Textures\n","Total count: 123\n","[49/123]\n","[99/123]\n","{'AUROC': 0.7261209487915039, 'AUPR-IN': 0.5729402303695679, 'AUPR-OUT': 0.8262160420417786, 'FPR95TPR': 0.724399983882904}\n","\n","LSUNCrop\n","Total count: 157\n","[49/157]\n","[99/157]\n","[149/157]\n","{'AUROC': 0.8569043874740601, 'AUPR-IN': 0.8468577861785889, 'AUPR-OUT': 0.8752673268318176, 'FPR95TPR': 0.460999995470047}\n","\n","TinyImageNetCrop\n","Total count: 157\n","[49/157]\n","[99/157]\n","[149/157]\n","{'AUROC': 0.8736330270767212, 'AUPR-IN': 0.862382709980011, 'AUPR-OUT': 0.8899842500686646, 'FPR95TPR': 0.42250001430511475}\n","\n","Places365\n","Total count: 364\n","[49/364]\n","[99/364]\n","[149/364]\n","[199/364]\n","[249/364]\n","[299/364]\n","[349/364]\n","{'AUROC': 0.7308443188667297, 'AUPR-IN': 0.8893899321556091, 'AUPR-OUT': 0.4916844069957733, 'FPR95TPR': 0.7105000019073486}\n","\n","GaussianNoise\n","Total count: 157\n","[49/157]\n","[99/157]\n","[149/157]\n","{'AUROC': 0.7796637415885925, 'AUPR-IN': 0.6548298001289368, 'AUPR-OUT': 0.853072464466095, 'FPR95TPR': 0.38909998536109924}\n","AUROC: 0.7690254350503286\n","FPR: 0.5739666620890299\n"]}]},{"cell_type":"markdown","source":["### Mahalanobis"],"metadata":{"id":"JSKhdtry0lXx"}},{"cell_type":"code","source":["model = WideResNet(num_classes=100, pretrained=\"cifar100-pt\").cuda().eval()\n","dataset_in_test = CIFAR100(root=\"data\", train=False, download=True, transform=trans)\n","loader_in_train = DataLoader(dataset_in_test, batch_size=128, num_workers=20)\n","\n","detector = Mahalanobis(model.features)\n","detector.fit(loader_in_train, device=\"cuda\")\n","results = test_with_all_datasets(detector, dataset_in_test)\n","\n","mean_AUROC = np.mean([r[\"AUROC\"] for r in results])\n","mean_FPR = np.mean([r[\"FPR95TPR\"] for r in results])\n","\n","print(\"AUROC:\", mean_AUROC)\n","print(\"FPR:\", mean_FPR)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6zsItSWm0pMd","outputId":"ba125208-3a01-473c-9f08-aa26c0d84d0a","executionInfo":{"status":"ok","timestamp":1712400042685,"user_tz":-540,"elapsed":235931,"user":{"displayName":"최다솔","userId":"02081007897853777168"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Files already downloaded and verified\n","Using downloaded and verified file: data/test_32x32.mat\n","\n","SVHN\n","Total count: 282\n","[49/282]\n","[99/282]\n","[149/282]\n","[199/282]\n","[249/282]\n","{'AUROC': 0.85689377784729, 'AUPR-IN': 0.9309223890304565, 'AUPR-OUT': 0.7334612607955933, 'FPR95TPR': 0.5418999791145325}\n","\n","Textures\n","Total count: 123\n","[49/123]\n","[99/123]\n","{'AUROC': 0.8992289304733276, 'AUPR-IN': 0.8528116345405579, 'AUPR-OUT': 0.9365952014923096, 'FPR95TPR': 0.4544000029563904}\n","\n","LSUNCrop\n","Total count: 157\n","[49/157]\n","[99/157]\n","[149/157]\n","{'AUROC': 0.5203654170036316, 'AUPR-IN': 0.4674402177333832, 'AUPR-OUT': 0.5986384749412537, 'FPR95TPR': 0.8277999758720398}\n","\n","TinyImageNetCrop\n","Total count: 157\n","[49/157]\n","[99/157]\n","[149/157]\n","{'AUROC': 0.5595657825469971, 'AUPR-IN': 0.4922320544719696, 'AUPR-OUT': 0.6488621830940247, 'FPR95TPR': 0.7591999769210815}\n","\n","Places365\n","Total count: 364\n","[49/364]\n","[99/364]\n","[149/364]\n","[199/364]\n","[249/364]\n","[299/364]\n","[349/364]\n","{'AUROC': 0.6392639875411987, 'AUPR-IN': 0.8424248099327087, 'AUPR-OUT': 0.35181185603141785, 'FPR95TPR': 0.8370000123977661}\n","\n","GaussianNoise\n","Total count: 157\n","[49/157]\n","[99/157]\n","[149/157]\n","{'AUROC': 0.9990980625152588, 'AUPR-IN': 0.9987039566040039, 'AUPR-OUT': 0.9993206858634949, 'FPR95TPR': 0.0032999999821186066}\n","AUROC: 0.7457359929879507\n","FPR: 0.5705999912073215\n"]}]},{"cell_type":"markdown","source":["### Energy"],"metadata":{"id":"E62hiDBA05mn"}},{"cell_type":"code","source":["model = WideResNet(num_classes=100, pretrained=\"cifar100-pt\").cuda().eval()\n","dataset_in_test = CIFAR100(root=\"data\", train=False, download=True, transform=trans)\n","loader_in_train = DataLoader(dataset_in_test, batch_size=128, num_workers=20)\n","\n","detector = EnergyBased(model)\n","detector.fit(loader_in_train, device=\"cuda\")\n","results = test_with_all_datasets(detector, dataset_in_test)\n","\n","mean_AUROC = np.mean([r[\"AUROC\"] for r in results])\n","mean_FPR = np.mean([r[\"FPR95TPR\"] for r in results])\n","\n","print(\"AUROC:\", mean_AUROC)\n","print(\"FPR:\", mean_FPR)"],"metadata":{"id":"0qzzz2sT2PxJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712400193225,"user_tz":-540,"elapsed":150544,"user":{"displayName":"최다솔","userId":"02081007897853777168"}},"outputId":"665f99c9-3908-47a2-de2d-c9e597d52656"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Files already downloaded and verified\n","Using downloaded and verified file: data/test_32x32.mat\n","\n","SVHN\n","Total count: 282\n","[49/282]\n","[99/282]\n","[149/282]\n","[199/282]\n","[249/282]\n","{'AUROC': 0.7387329339981079, 'AUPR-IN': 0.8501717448234558, 'AUPR-OUT': 0.5959532260894775, 'FPR95TPR': 0.6674000024795532}\n","\n","Textures\n","Total count: 123\n","[49/123]\n","[99/123]\n","{'AUROC': 0.7629623413085938, 'AUPR-IN': 0.6157165765762329, 'AUPR-OUT': 0.8509080410003662, 'FPR95TPR': 0.7124999761581421}\n","\n","LSUNCrop\n","Total count: 157\n","[49/157]\n","[99/157]\n","[149/157]\n","{'AUROC': 0.9588834643363953, 'AUPR-IN': 0.9571850895881653, 'AUPR-OUT': 0.9623993635177612, 'FPR95TPR': 0.20309999585151672}\n","\n","TinyImageNetCrop\n","Total count: 157\n","[49/157]\n","[99/157]\n","[149/157]\n","{'AUROC': 0.952881932258606, 'AUPR-IN': 0.9492186307907104, 'AUPR-OUT': 0.9575362205505371, 'FPR95TPR': 0.21170000731945038}\n","\n","Places365\n","Total count: 364\n","[49/364]\n","[99/364]\n","[149/364]\n","[199/364]\n","[249/364]\n","[299/364]\n","[349/364]\n","{'AUROC': 0.7581775784492493, 'AUPR-IN': 0.9042642116546631, 'AUPR-OUT': 0.5251756906509399, 'FPR95TPR': 0.7062000036239624}\n","\n","GaussianNoise\n","Total count: 157\n","[49/157]\n","[99/157]\n","[149/157]\n","{'AUROC': 0.7040618658065796, 'AUPR-IN': 0.5685272216796875, 'AUPR-OUT': 0.8121292591094971, 'FPR95TPR': 0.44999998807907104}\n","AUROC: 0.8126166860262553\n","FPR: 0.4918166622519493\n"]}]},{"cell_type":"markdown","source":["### Entropy"],"metadata":{"id":"MgA9G0ES2S5r"}},{"cell_type":"code","source":["model = WideResNet(num_classes=100, pretrained=\"cifar100-pt\").cuda().eval()\n","dataset_in_test = CIFAR100(root=\"data\", train=False, download=True, transform=trans)\n","loader_in_train = DataLoader(dataset_in_test, batch_size=128, num_workers=20)\n","\n","detector = Entropy(model)\n","detector.fit(loader_in_train, device=\"cuda\")\n","results = test_with_all_datasets(detector, dataset_in_test)\n","\n","mean_AUROC = np.mean([r[\"AUROC\"] for r in results])\n","mean_FPR = np.mean([r[\"FPR95TPR\"] for r in results])\n","\n","print(\"AUROC:\", mean_AUROC)\n","print(\"FPR:\", mean_FPR)"],"metadata":{"id":"2DLQd-K12WIf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712400344490,"user_tz":-540,"elapsed":151270,"user":{"displayName":"최다솔","userId":"02081007897853777168"}},"outputId":"7a6090eb-473b-47da-8545-15ec0a218bd5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Files already downloaded and verified\n","Using downloaded and verified file: data/test_32x32.mat\n","\n","SVHN\n","Total count: 282\n","[49/282]\n","[99/282]\n","[149/282]\n","[199/282]\n","[249/282]\n","{'AUROC': 0.7309297919273376, 'AUPR-IN': 0.8555963039398193, 'AUPR-OUT': 0.5878225564956665, 'FPR95TPR': 0.6890000104904175}\n","\n","Textures\n","Total count: 123\n","[49/123]\n","[99/123]\n","{'AUROC': 0.7506520748138428, 'AUPR-IN': 0.6022067070007324, 'AUPR-OUT': 0.8380107283592224, 'FPR95TPR': 0.7127000093460083}\n","\n","LSUNCrop\n","Total count: 157\n","[49/157]\n","[99/157]\n","[149/157]\n","{'AUROC': 0.892271101474762, 'AUPR-IN': 0.8919202089309692, 'AUPR-OUT': 0.8985163569450378, 'FPR95TPR': 0.4519999921321869}\n","\n","TinyImageNetCrop\n","Total count: 157\n","[49/157]\n","[99/157]\n","[149/157]\n","{'AUROC': 0.8988495469093323, 'AUPR-IN': 0.8950001001358032, 'AUPR-OUT': 0.9065179824829102, 'FPR95TPR': 0.4108000099658966}\n","\n","Places365\n","Total count: 364\n","[49/364]\n","[99/364]\n","[149/364]\n","[199/364]\n","[249/364]\n","[299/364]\n","[349/364]\n","{'AUROC': 0.7520604133605957, 'AUPR-IN': 0.9018186926841736, 'AUPR-OUT': 0.5070862174034119, 'FPR95TPR': 0.6998999714851379}\n","\n","GaussianNoise\n","Total count: 157\n","[49/157]\n","[99/157]\n","[149/157]\n","{'AUROC': 0.7952738404273987, 'AUPR-IN': 0.6608602404594421, 'AUPR-OUT': 0.8650186061859131, 'FPR95TPR': 0.37130001187324524}\n","AUROC: 0.8033394614855448\n","FPR: 0.5559500008821487\n"]}]},{"cell_type":"markdown","source":["### MaxLogit"],"metadata":{"id":"QO4o7REi2YLL"}},{"cell_type":"code","source":["model = WideResNet(num_classes=100, pretrained=\"cifar100-pt\").cuda().eval()\n","dataset_in_test = CIFAR100(root=\"data\", train=False, download=True, transform=trans)\n","loader_in_train = DataLoader(dataset_in_test, batch_size=128, num_workers=20)\n","\n","detector = MaxLogit(model)\n","detector.fit(loader_in_train, device=\"cuda\")\n","results = test_with_all_datasets(detector, dataset_in_test)\n","\n","mean_AUROC = np.mean([r[\"AUROC\"] for r in results])\n","mean_FPR = np.mean([r[\"FPR95TPR\"] for r in results])\n","\n","print(\"AUROC:\", mean_AUROC)\n","print(\"FPR:\", mean_FPR)"],"metadata":{"id":"9MeuW9YX2ct9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712400496975,"user_tz":-540,"elapsed":152488,"user":{"displayName":"최다솔","userId":"02081007897853777168"}},"outputId":"3709d712-7f0b-4e31-bd87-b2df1be22fb0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Files already downloaded and verified\n","Using downloaded and verified file: data/test_32x32.mat\n","\n","SVHN\n","Total count: 282\n","[49/282]\n","[99/282]\n","[149/282]\n","[199/282]\n","[249/282]\n","{'AUROC': 0.7395377159118652, 'AUPR-IN': 0.8536348342895508, 'AUPR-OUT': 0.5944435000419617, 'FPR95TPR': 0.6712999939918518}\n","\n","Textures\n","Total count: 123\n","[49/123]\n","[99/123]\n","{'AUROC': 0.7636523842811584, 'AUPR-IN': 0.6165502667427063, 'AUPR-OUT': 0.8512518405914307, 'FPR95TPR': 0.7138000130653381}\n","\n","LSUNCrop\n","Total count: 157\n","[49/157]\n","[99/157]\n","[149/157]\n","{'AUROC': 0.9514684677124023, 'AUPR-IN': 0.9468564987182617, 'AUPR-OUT': 0.9569815993309021, 'FPR95TPR': 0.21719999611377716}\n","\n","TinyImageNetCrop\n","Total count: 157\n","[49/157]\n","[99/157]\n","[149/157]\n","{'AUROC': 0.946761429309845, 'AUPR-IN': 0.940183162689209, 'AUPR-OUT': 0.9531491994857788, 'FPR95TPR': 0.22439999878406525}\n","\n","Places365\n","Total count: 364\n","[49/364]\n","[99/364]\n","[149/364]\n","[199/364]\n","[249/364]\n","[299/364]\n","[349/364]\n","{'AUROC': 0.759489893913269, 'AUPR-IN': 0.9050794839859009, 'AUPR-OUT': 0.5256511569023132, 'FPR95TPR': 0.7069000005722046}\n","\n","GaussianNoise\n","Total count: 157\n","[49/157]\n","[99/157]\n","[149/157]\n","{'AUROC': 0.7237257957458496, 'AUPR-IN': 0.5860793590545654, 'AUPR-OUT': 0.8226756453514099, 'FPR95TPR': 0.4300999939441681}\n","AUROC: 0.8141059478123983\n","FPR: 0.4939499994119008\n"]}]},{"cell_type":"markdown","source":["### KLMatching"],"metadata":{"id":"y6F1p3Yg2f-C"}},{"cell_type":"code","source":["model = WideResNet(num_classes=100, pretrained=\"cifar100-pt\").cuda().eval()\n","dataset_in_test = CIFAR100(root=\"data\", train=False, download=True, transform=trans)\n","loader_in_train = DataLoader(dataset_in_test, batch_size=128, num_workers=20)\n","\n","detector = KLMatching(model)\n","detector.fit(loader_in_train, device=\"cuda\")\n","results = test_with_all_datasets(detector, dataset_in_test)\n","\n","mean_AUROC = np.mean([r[\"AUROC\"] for r in results])\n","mean_FPR = np.mean([r[\"FPR95TPR\"] for r in results])\n","\n","print(\"AUROC:\", mean_AUROC)\n","print(\"FPR:\", mean_FPR)"],"metadata":{"id":"ydlWUSwS2i1R","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712400671853,"user_tz":-540,"elapsed":174900,"user":{"displayName":"최다솔","userId":"02081007897853777168"}},"outputId":"72d4bf94-cf35-4942-dbae-c89a892d5c6b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Files already downloaded and verified\n","Using downloaded and verified file: data/test_32x32.mat\n","\n","SVHN\n","Total count: 282\n","[49/282]\n","[99/282]\n","[149/282]\n","[199/282]\n","[249/282]\n","{'AUROC': 0.7014661431312561, 'AUPR-IN': 0.8676372170448303, 'AUPR-OUT': 0.4807525873184204, 'FPR95TPR': 0.7628999948501587}\n","\n","Textures\n","Total count: 123\n","[49/123]\n","[99/123]\n","{'AUROC': 0.7185306549072266, 'AUPR-IN': 0.6307766437530518, 'AUPR-OUT': 0.7842214107513428, 'FPR95TPR': 0.8511999845504761}\n","\n","LSUNCrop\n","Total count: 157\n","[49/157]\n","[99/157]\n","[149/157]\n","{'AUROC': 0.7772537469863892, 'AUPR-IN': 0.8041590452194214, 'AUPR-OUT': 0.6868447065353394, 'FPR95TPR': 0.945900022983551}\n","\n","TinyImageNetCrop\n","Total count: 157\n","[49/157]\n","[99/157]\n","[149/157]\n","{'AUROC': 0.8209725022315979, 'AUPR-IN': 0.8180630207061768, 'AUPR-OUT': 0.7937166094779968, 'FPR95TPR': 0.7091000080108643}\n","\n","Places365\n","Total count: 364\n","[49/364]\n","[99/364]\n","[149/364]\n","[199/364]\n","[249/364]\n","[299/364]\n","[349/364]\n","{'AUROC': 0.6605174541473389, 'AUPR-IN': 0.8806449770927429, 'AUPR-OUT': 0.2910478413105011, 'FPR95TPR': 0.921999990940094}\n","\n","GaussianNoise\n","Total count: 157\n","[49/157]\n","[99/157]\n","[149/157]\n","{'AUROC': 0.8127239346504211, 'AUPR-IN': 0.7409803867340088, 'AUPR-OUT': 0.8594106435775757, 'FPR95TPR': 0.42579999566078186}\n","AUROC: 0.7485774060090383\n","FPR: 0.7694833328326544\n"]}]},{"cell_type":"markdown","source":["### ViM"],"metadata":{"id":"mGpBvGYv2lCh"}},{"cell_type":"code","source":["model = WideResNet(num_classes=100, pretrained=\"cifar100-pt\").cuda().eval()\n","dataset_in_test = CIFAR100(root=\"data\", train=False, download=True, transform=trans)\n","loader_in_train = DataLoader(dataset_in_test, batch_size=128, num_workers=20)\n","\n","detector = ViM(model.features, d=64, w=model.fc.weight, b=model.fc.bias)\n","detector.fit(loader_in_train, device=\"cuda\")\n","results = test_with_all_datasets(detector, dataset_in_test)\n","\n","mean_AUROC = np.mean([r[\"AUROC\"] for r in results])\n","mean_FPR = np.mean([r[\"FPR95TPR\"] for r in results])\n","\n","print(\"AUROC:\", mean_AUROC)\n","print(\"FPR:\", mean_FPR)"],"metadata":{"id":"eUtI40gY2nxI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712400839057,"user_tz":-540,"elapsed":167208,"user":{"displayName":"최다솔","userId":"02081007897853777168"}},"outputId":"ff9178f0-ffab-42b5-e0ec-d5b62e430bf9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Files already downloaded and verified\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 20 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"output_type":"stream","name":"stdout","text":["Using downloaded and verified file: data/test_32x32.mat\n","\n","SVHN\n","Total count: 282\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 20 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"output_type":"stream","name":"stdout","text":["[49/282]\n","[99/282]\n","[149/282]\n","[199/282]\n","[249/282]\n","{'AUROC': 0.9254005551338196, 'AUPR-IN': 0.9664667844772339, 'AUPR-OUT': 0.8588016033172607, 'FPR95TPR': 0.32659998536109924}\n","\n","Textures\n","Total count: 123\n","[49/123]\n","[99/123]\n","{'AUROC': 0.9068517088890076, 'AUPR-IN': 0.8625251054763794, 'AUPR-OUT': 0.9417524337768555, 'FPR95TPR': 0.41929998993873596}\n","\n","LSUNCrop\n","Total count: 157\n","[49/157]\n","[99/157]\n","[149/157]\n","{'AUROC': 0.7555776238441467, 'AUPR-IN': 0.6573880910873413, 'AUPR-OUT': 0.811265766620636, 'FPR95TPR': 0.5440000295639038}\n","\n","TinyImageNetCrop\n","Total count: 157\n","[49/157]\n","[99/157]\n","[149/157]\n","{'AUROC': 0.7996347546577454, 'AUPR-IN': 0.715462863445282, 'AUPR-OUT': 0.8432332873344421, 'FPR95TPR': 0.48190000653266907}\n","\n","Places365\n","Total count: 364\n","[49/364]\n","[99/364]\n","[149/364]\n","[199/364]\n","[249/364]\n","[299/364]\n","[349/364]\n","{'AUROC': 0.7013358473777771, 'AUPR-IN': 0.8769044280052185, 'AUPR-OUT': 0.41298708319664, 'FPR95TPR': 0.7990999817848206}\n","\n","GaussianNoise\n","Total count: 157\n","[49/157]\n","[99/157]\n","[149/157]\n","{'AUROC': 0.9988005757331848, 'AUPR-IN': 0.9984657168388367, 'AUPR-OUT': 0.9990701675415039, 'FPR95TPR': 0.004399999976158142}\n","AUROC: 0.8479335109392802\n","FPR: 0.4292166655262311\n"]}]},{"cell_type":"markdown","source":["### Outlier Exposure (OE)"],"metadata":{"id":"eB0PNIWpF1yE"}},{"cell_type":"code","source":["from torch.optim import Adam\n","from pytorch_ood.dataset.img import Textures, TinyImages300k\n","from pytorch_ood.detector import MaxSoftmax\n","from pytorch_ood.loss import OutlierExposureLoss\n","from pytorch_ood.utils import OODMetrics, ToUnknown\n","\n","torch.manual_seed(123)\n","\n","# maximum number of epochs and training iterations\n","n_epochs = 10\n","device = \"cuda:0\"\n","\n","# %%\n","# Setup preprocessing and data\n","trans = tvt.Compose([tvt.Resize(size=(32, 32)), tvt.ToTensor()])\n","\n","# setup IN training data\n","dataset_in_train = CIFAR100(root=\"data\", train=True, download=True, transform=trans)\n","\n","# setup OOD training data, use ToUnknown() to mark labels as OOD\n","# this way, outlier exposure can automatically decide if the training samples are IN or OOD\n","dataset_out_train = TinyImages300k(\n","    root=\"data\", download=True, transform=trans, target_transform=ToUnknown()\n",")\n","\n","# setup IN test data\n","dataset_in_test = CIFAR100(root=\"data\", train=False, transform=trans)\n","\n","# setup OOD test data, use ToUnknown() to mark labels as OOD\n","dataset_out_test = Textures(\n","    root=\"data\", download=True, transform=trans, target_transform=ToUnknown()\n",")\n","\n","# create data loaders\n","train_loader = DataLoader(\n","    dataset_in_train + dataset_out_train, batch_size=64, shuffle=True\n",")\n","test_loader = DataLoader(dataset_in_test + dataset_out_test, batch_size=64)\n","\n","# %%\n","# Create DNN, pretrained on the imagenet excluding cifar100 classes\n","model = WideResNet(num_classes=1000, pretrained=\"imagenet32-nocifar\")\n","# we have to replace the final layer to account for the lower number of\n","# classes in the CIFAR100 dataset\n","model.fc = torch.nn.Linear(model.fc.in_features, 100)\n","\n","model.to(device)\n","\n","opti = Adam(model.parameters())\n","criterion = OutlierExposureLoss(alpha=0.5)\n","\n","\n","# %%\n","# Define a function to test the model\n","def test():\n","    softmax = MaxSoftmax(model)\n","\n","    metrics_softmax = OODMetrics()\n","    model.eval()\n","\n","    with torch.no_grad():\n","        for x, y in test_loader:\n","            metrics_softmax.update(softmax(x.to(device)), y)\n","\n","    print(metrics_softmax.compute())\n","    model.train()\n","\n","\n","# %%\n","# Start training\n","for epoch in range(n_epochs):\n","    print(f\"Epoch {epoch}\")\n","    for x, y in train_loader:\n","        logits = model(x.to(device))\n","        loss = criterion(logits, y.to(device))\n","        opti.zero_grad()\n","        loss.backward()\n","        opti.step()\n","\n","    test()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Yy9n9B2pzD7A","executionInfo":{"status":"ok","timestamp":1712488795523,"user_tz":-540,"elapsed":2994353,"user":{"displayName":"최다솔(일반대학원 디지털애널리틱스 융합협동과정)","userId":"06217896809786522271"}},"outputId":"cfaff64a-e699-47ac-b8af-96b818386ca0"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Files already downloaded and verified\n","Epoch 0\n","{'AUROC': 0.6468272805213928, 'AUPR-IN': 0.5213726758956909, 'AUPR-OUT': 0.7458751201629639, 'FPR95TPR': 0.8876000046730042}\n","Epoch 1\n","{'AUROC': 0.8347277641296387, 'AUPR-IN': 0.7417207956314087, 'AUPR-OUT': 0.8896232843399048, 'FPR95TPR': 0.6370999813079834}\n","Epoch 2\n","{'AUROC': 0.7767816781997681, 'AUPR-IN': 0.6278778314590454, 'AUPR-OUT': 0.850523829460144, 'FPR95TPR': 0.6934000253677368}\n","Epoch 3\n","{'AUROC': 0.823417067527771, 'AUPR-IN': 0.7490994334220886, 'AUPR-OUT': 0.8821779489517212, 'FPR95TPR': 0.6647999882698059}\n","Epoch 4\n","{'AUROC': 0.8599973320960999, 'AUPR-IN': 0.7726024389266968, 'AUPR-OUT': 0.9102161526679993, 'FPR95TPR': 0.5281000137329102}\n","Epoch 5\n","{'AUROC': 0.8633450269699097, 'AUPR-IN': 0.7908233404159546, 'AUPR-OUT': 0.9105650186538696, 'FPR95TPR': 0.5515999794006348}\n","Epoch 6\n","{'AUROC': 0.8534408807754517, 'AUPR-IN': 0.7555985450744629, 'AUPR-OUT': 0.9091955423355103, 'FPR95TPR': 0.5296000242233276}\n","Epoch 7\n","{'AUROC': 0.8800964951515198, 'AUPR-IN': 0.8157627582550049, 'AUPR-OUT': 0.9142497181892395, 'FPR95TPR': 0.510699987411499}\n","Epoch 8\n","{'AUROC': 0.9083331823348999, 'AUPR-IN': 0.856525719165802, 'AUPR-OUT': 0.941351592540741, 'FPR95TPR': 0.3953999876976013}\n","Epoch 9\n","{'AUROC': 0.8684343099594116, 'AUPR-IN': 0.7733821272850037, 'AUPR-OUT': 0.915361762046814, 'FPR95TPR': 0.47769999504089355}\n"]}]},{"cell_type":"code","source":["def test(test_loader, name):\n","    softmax = MaxSoftmax(model)\n","\n","    metrics_softmax = OODMetrics()\n","    model.eval()\n","\n","    with torch.no_grad():\n","        for x, y in test_loader:\n","            metrics_softmax.update(softmax(x.to(device)), y)\n","    print(name)\n","    print(metrics_softmax.compute())"],"metadata":{"id":"Ji_oGp5mDrHj","executionInfo":{"status":"ok","timestamp":1712488796404,"user_tz":-540,"elapsed":6,"user":{"displayName":"최다솔(일반대학원 디지털애널리틱스 융합협동과정)","userId":"06217896809786522271"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["dataset_names = [\"SVHN\", \"Textures\", \"LSUNCrop\", \"TinyImageNetCrop\", \"Places365\", \"GaussianNoise\"]\n","datasets_out_test = {\n","    \"SVHN\": SVHN(root=\"./data\", split=\"test\", download=True, transform=trans, target_transform=ToUnknown()),\n","    \"Textures\": Textures(root=\"./data\", download=True, transform=trans, target_transform=ToUnknown()),\n","    \"LSUNCrop\": LSUNCrop(root=\"./data\", download=True, transform=trans, target_transform=ToUnknown()),\n","    \"TinyImageNetCrop\": TinyImageNetCrop(root=\"./data\", download=True, transform=trans, target_transform=ToUnknown()),\n","    \"Places365\": Places365(root=\"./data\", split=\"val\", small=True, download=False, transform=trans, target_transform=ToUnknown()),\n","    \"GaussianNoise\": GaussianNoise(length=10000, transform=trans, target_transform=ToUnknown())\n","}\n","\n","for name, dataset in datasets_out_test.items():\n","    dataset_in_test =  CIFAR100(root=\"data\", train=False, transform=trans)\n","    test_loader = DataLoader(dataset_in_test + dataset, batch_size=64)\n","    test(test_loader, name)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l3x_yV7UzirF","executionInfo":{"status":"ok","timestamp":1712488964262,"user_tz":-540,"elapsed":167862,"user":{"displayName":"최다솔(일반대학원 디지털애널리틱스 융합협동과정)","userId":"06217896809786522271"}},"outputId":"1b62f4f6-623e-47b6-b1ac-d5546d5579b8"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Using downloaded and verified file: ./data/test_32x32.mat\n","SVHN\n","{'AUROC': 0.9353353977203369, 'AUPR-IN': 0.9653217792510986, 'AUPR-OUT': 0.8990997076034546, 'FPR95TPR': 0.22689999639987946}\n","Textures\n","{'AUROC': 0.8684343099594116, 'AUPR-IN': 0.7733821272850037, 'AUPR-OUT': 0.915361762046814, 'FPR95TPR': 0.47769999504089355}\n","LSUNCrop\n","{'AUROC': 0.9128215909004211, 'AUPR-IN': 0.896831750869751, 'AUPR-OUT': 0.9203508496284485, 'FPR95TPR': 0.3393000066280365}\n","TinyImageNetCrop\n","{'AUROC': 0.9196836948394775, 'AUPR-IN': 0.9047382473945618, 'AUPR-OUT': 0.9285298585891724, 'FPR95TPR': 0.3073999881744385}\n","Places365\n","{'AUROC': 0.8459770679473877, 'AUPR-IN': 0.9435319900512695, 'AUPR-OUT': 0.6646593809127808, 'FPR95TPR': 0.5497999787330627}\n","GaussianNoise\n","{'AUROC': 0.9485790133476257, 'AUPR-IN': 0.8635244369506836, 'AUPR-OUT': 0.9705520272254944, 'FPR95TPR': 0.07900000363588333}\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"f-n3s4zUDxk_"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}