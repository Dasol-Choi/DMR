{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50d1d2c8-1a65-4fc6-a406-21f0321bd025",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2,3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6316aa98-efbc-404f-9d6a-bcd6b0d08659",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "mean = [x / 255 for x in [125.3, 123.0, 113.9]]\n",
    "std = [x / 255 for x in [63.0, 62.1, 66.7]]\n",
    "\n",
    "trans = transforms.Compose([\n",
    "    transforms.Resize(32),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(std=std, mean=mean)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9527b6bd-d3e2-48d8-b0e5-cc07353e1a7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Size of training dataset: 50000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision.datasets import CIFAR10\n",
    "\n",
    "batch_size = 1\n",
    "\n",
    "train_dataset = CIFAR10(root=\"data\", train=True, download=True, transform=trans)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=False, num_workers=16)\n",
    "\n",
    "print(\"Size of training dataset:\", len(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6880d781-d0ea-4f8b-b9ee-ad05aa1e4164",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_ood.model import WideResNet\n",
    "from torchcam.methods import LayerCAM\n",
    "\n",
    "num_classes = 10\n",
    "img_size = 32\n",
    "input_shape = (3, img_size, img_size)\n",
    "\n",
    "model = WideResNet(num_classes=num_classes, pretrained=\"cifar10-pt\").cuda().eval()\n",
    "target_layer = model.block3\n",
    "localize_net = LayerCAM(model, target_layer=target_layer, input_shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2af099c1-e1e2-46bb-acef-0639b9cf09bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 50000/50000 [25:30<00:00, 32.68it/s]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "cam_lambda = 0.3\n",
    "save_dir = os.path.join(f\"./cifar10_KIRBY/ood_training_images\")\n",
    "\n",
    "# Generate the folder to save the processed images.\n",
    "for class_idx in range(num_classes):\n",
    "    os.makedirs(os.path.join(save_dir, str(class_idx)), exist_ok=True)\n",
    "\n",
    "for batch_idx, (data, target) in enumerate(tqdm(train_loader)):\n",
    "    if torch.cuda.is_available():\n",
    "        data = data.cuda()\n",
    "        target = target.cuda()\n",
    "\n",
    "    # Forward the original images.\n",
    "    out = model(data)\n",
    "    # Calculate the Class Activation Map (CAM) using the outputs of the model.\n",
    "    activation_map = localize_net(out.squeeze(0).argmax().item(), out)\n",
    "    activation_map = activation_map[0].squeeze().detach().cpu().numpy()\n",
    "\n",
    "    # Resize the resolution of activation maps as the same size of images.\n",
    "    if activation_map.shape[0] != img_size:\n",
    "        x = cv2.resize(activation_map, (img_size, img_size))\n",
    "    else:\n",
    "        x = activation_map\n",
    "    activation_map = x\n",
    "\n",
    "    # Save the original images as NumPy objects.\n",
    "    x_data_array = np.transpose(data.detach().cpu().numpy(), [0, 2, 3, 1])\n",
    "    origin_x_data = (x_data_array * np.array(std).reshape([1, 1, 1, 3])) + np.array(mean).reshape([1, 1, 1, 3])\n",
    "    origin_x_data = np.uint8(origin_x_data * 255)[0]\n",
    "    \n",
    "    # Get mask images in which the regions whose values are lower than the threshold are masked.\n",
    "    background_mask = np.uint8(activation_map < cam_lambda)\n",
    "    # Remove the masked area.\n",
    "    remove_image = np.copy(origin_x_data) * np.expand_dims(background_mask, axis=-1)\n",
    "    # Generate target mask images for in-painting.\n",
    "    target_mask = -1 * (background_mask.astype(np.float32) - 1.)\n",
    "    # Generate the synthesized OOD images using the FS (Fast Marching) in-painting method.\n",
    "    inpaint = cv2.inpaint(remove_image, target_mask.astype(np.uint8), 5, cv2.INPAINT_TELEA)\n",
    "\n",
    "    # Save the final synthesized OOD training images.\n",
    "    class_idx = target.detach().cpu().numpy().flatten()[0]\n",
    "\n",
    "    # When we use the ImageFolder library, it is recommended to use the reverse class_to_idx map.\n",
    "    save_original_train_path = os.path.join(save_dir, str(idx_to_class[class_idx]), f\"{batch_idx}_{class_idx}_{str(cam_lambda)}_original.png\")\n",
    "    save_ood_train_path = os.path.join(save_dir, str(idx_to_class[class_idx]), f\"{batch_idx}_{class_idx}_{str(cam_lambda)}_train.png\")\n",
    "    save_ood_mask_path = os.path.join(save_dir, str(idx_to_class[class_idx]), f\"{batch_idx}_{idx_to_class[class_idx]}_{str(cam_lambda)}_mask.png\")\n",
    "\n",
    "    cv2.imwrite(save_original_train_path, origin_x_data[..., ::-1].astype(np.uint8))\n",
    "    cv2.imwrite(save_ood_mask_path, (target_mask * 255).astype(np.uint8))\n",
    "    cv2.imwrite(save_ood_train_path, inpaint[..., ::-1].astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f6c7b826-5d98-4b8d-bfd6-d7d7e8a59302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of file: 15000 for the label 0\n",
      "The number of file: 15000 for the label 1\n",
      "The number of file: 15000 for the label 2\n",
      "The number of file: 15000 for the label 3\n",
      "The number of file: 15000 for the label 4\n",
      "The number of file: 15000 for the label 5\n",
      "The number of file: 15000 for the label 6\n",
      "The number of file: 15000 for the label 7\n",
      "The number of file: 15000 for the label 8\n",
      "The number of file: 15000 for the label 9\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Verify the number of images per each class.\n",
    "for i in range(num_classes):\n",
    "    directory = f\"{save_dir}/{i}\"\n",
    "    cnt = 0\n",
    "    # Iterate all image paths for a certain label.\n",
    "    for path in os.listdir(directory):\n",
    "        # Count all the image files.\n",
    "        if os.path.isfile(os.path.join(directory, path)):\n",
    "            cnt += 1\n",
    "    # Print the number of files per label.\n",
    "    print(f\"The number of file: {cnt} for the label {i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a7e5a5d4-fc67-4786-bb70-ae1cd0ed34f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "593M\t./cifar10_KIRBY/ood_training_images\n"
     ]
    }
   ],
   "source": [
    "!du -hs ./cifar10_KIRBY/ood_training_images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96738b43-b3f8-453d-a972-1d226147e5f9",
   "metadata": {},
   "source": [
    "#### <b>(Option) Remove Unnecessary Files</b>\n",
    "\n",
    "<pre>\n",
    "import os\n",
    "\n",
    "dir_name = \"./cifar10_KIRBY/ood_training_images\"\n",
    "\n",
    "for i in range(num_classes):\n",
    "    test = os.listdir(dir_name + \"/\" + str(i))\n",
    "    for item in test:\n",
    "        if item.endswith(\"_original.png\") or item.endswith(\"_mask.png\"):\n",
    "            os.remove(os.path.join(dir_name + \"/\" + str(i) + \"/\" + item))\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3f37c5-261b-4acb-be84-5f2ac6fcecb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!du -hs ./cifar10_KIRBY/ood_training_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415ae70b-232b-4e22-b101-a3ca53bd0d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "!zip -r output.zip ./cifar10_KIRBY/ood_training_images"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
